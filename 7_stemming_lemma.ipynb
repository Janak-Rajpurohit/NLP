{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEMMING - Using fix rules to like remove ing,able to convert to base word\n",
    "# walking ->walk  (just remove ing)\n",
    "# adjustable -> adjust (just remove able)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMMATIZATION - here we use knowledge of lang to convert to base word \n",
    "# here we can't just remove ing and able to convert to base word\n",
    "# ate -> eat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY has no stemming support, inly lemmatization \n",
    "# NLTK has both supporrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# obj =  class()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n",
      "better  |  better\n"
     ]
    }
   ],
   "source": [
    "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting','better']\n",
    "for word in words:\n",
    "    print(word,\" | \",stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating eats eat ate adjustable rafting ability meeting better'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(words)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat  |  9837207709914848172\n",
      "eats  |  eat  |  9837207709914848172\n",
      "eat  |  eat  |  9837207709914848172\n",
      "ate  |  eat  |  9837207709914848172\n",
      "adjustable  |  adjustable  |  6033511944150694480\n",
      "rafting  |  raft  |  7154368781129989833\n",
      "ability  |  ability  |  11565809527369121409\n",
      "meeting  |  meeting  |  14798207169164081740\n",
      "better  |  well  |  4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_,\" | \",token.lemma)     #lemma gives unique hash of token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mando  |  Mando  |  7837215228004622142\n",
      "talked  |  talk  |  13939146775466599234\n",
      "for  |  for  |  16037325823156266367\n",
      "3  |  3  |  602994839685422785\n",
      "hours  |  hour  |  9748623380567160636\n",
      "although  |  although  |  343236316598008647\n",
      "talking  |  talk  |  13939146775466599234\n",
      "is  |  be  |  10382539506755952630\n",
      "n't  |  not  |  447765159362469301\n",
      "his  |  his  |  2661093235354845946\n",
      "thing  |  thing  |  2473243759842082748\n",
      "he  |  he  |  1655312771067108281\n",
      "became  |  become  |  12558846041070486771\n",
      "talkative  |  talkative  |  13364764166055324990\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing he became talkative\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_,\" | \",token.lemma)     #lemma gives unique hash of token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bro  |  Brah\n"
     ]
    }
   ],
   "source": [
    "# attribute_ruler - assign attribute to token we can customize it\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "# here it is slang bro = brah , lemmatizerr doesn't convert it to same word \n",
    "print(doc[0].lemma_,\" | \",doc[6].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brother\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "# so we will customize it\n",
    "ar = nlp.get_pipe(\"attribute_ruler\")\n",
    "# for bro and brah i want there lemma to be Brother\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
